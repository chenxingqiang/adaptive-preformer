model:
  input_dim: 64
  d_model: 256
  nhead: 8
  num_layers: 6
  dropout: 0.1

training:
  batch_size: 32
  num_epochs: 100
  learning_rate: 1e-4
  weight_decay: 0.01
  warmup_epochs: 10
  gradient_clip: 1.0

data:
  sequence_length: 512
  train_val_split: 0.8
  num_workers: 4

logging:
  save_dir: "checkpoints"
  log_interval: 100
  eval_interval: 1

